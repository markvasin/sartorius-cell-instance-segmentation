{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install numpy==1.21.3","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:19:38.791239Z","iopub.execute_input":"2021-10-25T10:19:38.792498Z","iopub.status.idle":"2021-10-25T10:19:54.857079Z","shell.execute_reply.started":"2021-10-25T10:19:38.792439Z","shell.execute_reply":"2021-10-25T10:19:54.855911Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.express as px\nfrom PIL import Image, ImageEnhance\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-25T10:19:54.859938Z","iopub.execute_input":"2021-10-25T10:19:54.860349Z","iopub.status.idle":"2021-10-25T10:19:56.557799Z","shell.execute_reply.started":"2021-10-25T10:19:54.860295Z","shell.execute_reply":"2021-10-25T10:19:56.556703Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Loading Data","metadata":{}},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/sartorius-cell-instance-segmentation\"\n\n# LIVECELL extra dataset\nLIVECELL_DIR = os.path.join(DATA_DIR, \"LIVECelldataset_2021\")\nLIVECELL_ANN_DIR = os.path.join(LIVECELL_DIR, \"annotations\")\nLIVECELL_IMG_DIR = os.path.join(LIVECELL_DIR, \"images\")\n\n# Dataset\nTRAIN_DIR = os.path.join(DATA_DIR, \"train\")\nTEST_DIR = os.path.join(DATA_DIR, \"test\")\nSEMI_DIR = os.path.join(DATA_DIR, \"train_semi_supervised\")\nTRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:19:56.559838Z","iopub.execute_input":"2021-10-25T10:19:56.560179Z","iopub.status.idle":"2021-10-25T10:19:56.568174Z","shell.execute_reply.started":"2021-10-25T10:19:56.560134Z","shell.execute_reply":"2021-10-25T10:19:56.566929Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(TRAIN_CSV)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:21:02.215100Z","iopub.execute_input":"2021-10-25T10:21:02.215439Z","iopub.status.idle":"2021-10-25T10:21:02.579514Z","shell.execute_reply.started":"2021-10-25T10:21:02.215404Z","shell.execute_reply":"2021-10-25T10:21:02.578682Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Inspecting train dataframe","metadata":{}},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:19:57.207143Z","iopub.execute_input":"2021-10-25T10:19:57.207433Z","iopub.status.idle":"2021-10-25T10:19:57.295087Z","shell.execute_reply.started":"2021-10-25T10:19:57.207399Z","shell.execute_reply":"2021-10-25T10:19:57.294482Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:19:57.296453Z","iopub.execute_input":"2021-10-25T10:19:57.296910Z","iopub.status.idle":"2021-10-25T10:19:57.302695Z","shell.execute_reply.started":"2021-10-25T10:19:57.296875Z","shell.execute_reply":"2021-10-25T10:19:57.301792Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_df['cell_type'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:19:57.304215Z","iopub.execute_input":"2021-10-25T10:19:57.304468Z","iopub.status.idle":"2021-10-25T10:19:57.325314Z","shell.execute_reply.started":"2021-10-25T10:19:57.304439Z","shell.execute_reply":"2021-10-25T10:19:57.324622Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Visiualize distribution","metadata":{}},{"cell_type":"code","source":"def plot_distribution(x):\n    fig = px.histogram(\n    train_df, \n    x = x,\n    width = 800,\n    height = 500)\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:19:57.326366Z","iopub.execute_input":"2021-10-25T10:19:57.327242Z","iopub.status.idle":"2021-10-25T10:19:57.332974Z","shell.execute_reply.started":"2021-10-25T10:19:57.327203Z","shell.execute_reply":"2021-10-25T10:19:57.331822Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"plot_distribution('cell_type')","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:19:57.334899Z","iopub.execute_input":"2021-10-25T10:19:57.335911Z","iopub.status.idle":"2021-10-25T10:19:59.175204Z","shell.execute_reply.started":"2021-10-25T10:19:57.335863Z","shell.execute_reply":"2021-10-25T10:19:59.174427Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"plot_distribution('plate_time')","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:19:59.177959Z","iopub.execute_input":"2021-10-25T10:19:59.178242Z","iopub.status.idle":"2021-10-25T10:20:00.052091Z","shell.execute_reply.started":"2021-10-25T10:19:59.178209Z","shell.execute_reply":"2021-10-25T10:20:00.050887Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"plot_distribution('elapsed_timedelta')","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:20:00.053587Z","iopub.execute_input":"2021-10-25T10:20:00.053853Z","iopub.status.idle":"2021-10-25T10:20:00.944435Z","shell.execute_reply.started":"2021-10-25T10:20:00.053821Z","shell.execute_reply":"2021-10-25T10:20:00.942710Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"plot_distribution('id')","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:20:00.946236Z","iopub.execute_input":"2021-10-25T10:20:00.946583Z","iopub.status.idle":"2021-10-25T10:20:01.655805Z","shell.execute_reply.started":"2021-10-25T10:20:00.946537Z","shell.execute_reply":"2021-10-25T10:20:01.654881Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Analyse statistic of images and annotations","metadata":{}},{"cell_type":"code","source":"train_df['cell_type'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:20:01.657346Z","iopub.execute_input":"2021-10-25T10:20:01.657595Z","iopub.status.idle":"2021-10-25T10:20:01.675007Z","shell.execute_reply.started":"2021-10-25T10:20:01.657563Z","shell.execute_reply":"2021-10-25T10:20:01.674404Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_df.nunique()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:20:01.676290Z","iopub.execute_input":"2021-10-25T10:20:01.676514Z","iopub.status.idle":"2021-10-25T10:20:01.810152Z","shell.execute_reply.started":"2021-10-25T10:20:01.676489Z","shell.execute_reply":"2021-10-25T10:20:01.809054Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_df['id'].value_counts().describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:20:01.811411Z","iopub.execute_input":"2021-10-25T10:20:01.811655Z","iopub.status.idle":"2021-10-25T10:20:01.833551Z","shell.execute_reply.started":"2021-10-25T10:20:01.811628Z","shell.execute_reply":"2021-10-25T10:20:01.832523Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['cell_type'] == 'shsy5y'].nunique()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:20:01.834823Z","iopub.execute_input":"2021-10-25T10:20:01.835893Z","iopub.status.idle":"2021-10-25T10:20:01.937365Z","shell.execute_reply.started":"2021-10-25T10:20:01.835841Z","shell.execute_reply":"2021-10-25T10:20:01.936295Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['cell_type'] == 'astro'].nunique()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:20:01.938655Z","iopub.execute_input":"2021-10-25T10:20:01.938894Z","iopub.status.idle":"2021-10-25T10:20:01.987255Z","shell.execute_reply.started":"2021-10-25T10:20:01.938866Z","shell.execute_reply":"2021-10-25T10:20:01.986195Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['cell_type'] == 'cort'].nunique()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:20:01.988504Z","iopub.execute_input":"2021-10-25T10:20:01.988781Z","iopub.status.idle":"2021-10-25T10:20:02.028637Z","shell.execute_reply.started":"2021-10-25T10:20:01.988752Z","shell.execute_reply":"2021-10-25T10:20:02.027689Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['cell_type'] == 'shsy5y']['id'].value_counts().describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:20:02.029906Z","iopub.execute_input":"2021-10-25T10:20:02.030153Z","iopub.status.idle":"2021-10-25T10:20:02.070798Z","shell.execute_reply.started":"2021-10-25T10:20:02.030126Z","shell.execute_reply":"2021-10-25T10:20:02.069675Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['cell_type'] == 'astro']['id'].value_counts().describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:20:02.072376Z","iopub.execute_input":"2021-10-25T10:20:02.072648Z","iopub.status.idle":"2021-10-25T10:20:02.101547Z","shell.execute_reply.started":"2021-10-25T10:20:02.072603Z","shell.execute_reply":"2021-10-25T10:20:02.100528Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['cell_type'] == 'cort']['id'].value_counts().describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:20:02.103226Z","iopub.execute_input":"2021-10-25T10:20:02.103758Z","iopub.status.idle":"2021-10-25T10:20:02.130118Z","shell.execute_reply.started":"2021-10-25T10:20:02.103710Z","shell.execute_reply":"2021-10-25T10:20:02.129506Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Data Summary\n* There are three classes: shsy5y, astro, cort\n* There are 606 training images\n* There are 240 hidden test images\n* All images has width of 704, height of 520\n* Number of annotations: shsy5y=52286, astro=10522, cort=10777, total=73585\n    * This is an imbalance dataset\n    * There are in average 121 labels of cell per image\n        * Average labels/image for shsy5y: 337\n        * Average labels/image for astro: 80\n        * Average labels/image for cort: 33\n* There are three types of cells represented in the images, but only one type per image\n    * There are 320 images with CELL_TYPE=cort\n    * There are 155 images with CELL_TYPE=shsy5y\n    * There are 131 images with CELL_TYPE=astro","metadata":{}},{"cell_type":"markdown","source":"## Visualize dataset","metadata":{}},{"cell_type":"markdown","source":"### Helper Functions\nFrom https://www.kaggle.com/dschettler8845/sartorius-segmentation-eda-effdet-tf-train#helper_functions\n- RLE encoder/decoder\n- Visualizer","metadata":{"execution":{"iopub.status.busy":"2021-10-24T13:52:19.261260Z","iopub.execute_input":"2021-10-24T13:52:19.262004Z","iopub.status.idle":"2021-10-24T13:52:19.266457Z","shell.execute_reply.started":"2021-10-24T13:52:19.261960Z","shell.execute_reply":"2021-10-24T13:52:19.265480Z"}}},{"cell_type":"code","source":"# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n# modified from: https://www.kaggle.com/inversion/run-length-decoding-quick-start\ndef rle_decode(mask_rle, shape, color=1):\n    \"\"\" TBD\n    \n    Args:\n        mask_rle (str): run-length as string formated (start length)\n        shape (tuple of ints): (height,width) of array to return \n    \n    Returns: \n        Mask (np.array)\n            - 1 indicating mask\n            - 0 indicating background\n\n    \"\"\"\n    # Split the string by space, then convert it into a integer array\n    s = np.array(mask_rle.split(), dtype=int)\n\n    # Every even value is the start, every odd value is the \"run\" length\n    starts = s[0::2] - 1\n    lengths = s[1::2]\n    ends = starts + lengths\n\n    # The image image is actually flattened since RLE is a 1D \"run\"\n    if len(shape)==3:\n        h, w, d = shape\n        img = np.zeros((h * w, d), dtype=np.float32)\n    else:\n        h, w = shape\n        img = np.zeros((h * w,), dtype=np.float32)\n\n    # The color here is actually just any integer you want!\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n        \n    # Don't forget to change the image back to the original shape\n    return img.reshape(shape)\n\ndef get_img_and_mask(img_path, annotation, width, height, mask_only=False, rle_fn=rle_decode):\n    \"\"\" Capture the relevant image array as well as the image mask \"\"\"\n    img_mask = np.zeros((height, width), dtype=np.uint8)\n    for i, annot in enumerate(annotation): \n        img_mask = np.where(rle_fn(annot, (height, width))!=0, i, img_mask)\n    \n    # Early Exit\n    if mask_only:\n        return img_mask\n    \n    # Else Return images\n    img = cv2.imread(img_path)[..., ::-1]\n    return img[..., 0], img_mask\n\ndef plot_img_and_mask(img, mask, bboxes=None, invert_img=True, boost_contrast=True):\n    \"\"\" Function to take an image and the corresponding mask and plot\n    \n    Args:\n        img (np.arr): 1 channel np arr representing the image of cellular structures\n        mask (np.arr): 1 channel np arr representing the instance masks (incrementing by one)\n        bboxes (list of tuples, optional): (tl, br) coordinates of enclosing bboxes\n        invert_img (bool, optional): Whether or not to invert the base image\n        boost_contrast (bool, optional): Whether or not to boost contrast of the base image\n        \n    Returns:\n        None; Plots the two arrays and overlays them to create a merged image\n    \"\"\"\n    plt.figure(figsize=(20,10))\n    \n    plt.subplot(1,3,1)\n    _img = np.tile(np.expand_dims(img, axis=-1), 3)\n    \n    # Flip black-->white ... white-->black\n    if invert_img:\n        _img = _img.max()-_img\n    \n    if boost_contrast:\n        _img = np.asarray(ImageEnhance.Contrast(Image.fromarray(_img)).enhance(16))\n    \n    if bboxes:\n        for i, bbox in enumerate(bboxes):\n            mask = cv2.rectangle(mask, bbox[0], bbox[1], (i+1, 0, 0), thickness=2)\n    \n    plt.imshow(_img)\n    plt.axis(False)\n    plt.title(\"Cell Image\", fontweight=\"bold\")\n    \n    plt.subplot(1,3,2)\n    _mask = np.zeros_like(_img)\n    _mask[..., 0] = mask\n    plt.imshow(mask, cmap=\"inferno\")\n    plt.axis(False)\n    plt.title(\"Instance Segmentation Mask\", fontweight=\"bold\")\n    \n    merged = cv2.addWeighted(_img, 0.75, np.clip(_mask, 0, 1)*255, 0.25, 0.0,)\n    plt.subplot(1,3,3)\n    plt.imshow(merged)\n    plt.axis(False)\n    plt.title(\"Cell Image w/ Instance Segmentation Mask Overlay\", fontweight=\"bold\")\n    \n    plt.tight_layout()\n    plt.show()\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:20:02.131234Z","iopub.execute_input":"2021-10-25T10:20:02.132088Z","iopub.status.idle":"2021-10-25T10:20:02.152064Z","shell.execute_reply.started":"2021-10-25T10:20:02.132048Z","shell.execute_reply":"2021-10-25T10:20:02.151264Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Prepare dataframe for visualizing\ntrain_df = pd.read_csv(TRAIN_CSV)\ntrain_df[\"img_path\"] = train_df[\"id\"].apply(lambda x: os.path.join(TRAIN_DIR, x + \".png\")) # Capture Image Path As Well\ntmp_df = train_df.drop_duplicates(subset=[\"id\", \"img_path\"]).reset_index(drop=True)\ntmp_df[\"annotation\"] = train_df.groupby(\"id\")[\"annotation\"].agg(list).reset_index(drop=True)\ntrain_df = tmp_df.copy()\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:21:15.921402Z","iopub.execute_input":"2021-10-25T10:21:15.922541Z","iopub.status.idle":"2021-10-25T10:21:16.544035Z","shell.execute_reply.started":"2021-10-25T10:21:15.922487Z","shell.execute_reply":"2021-10-25T10:21:16.543015Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"index = 0\ndisplay(train_df.iloc[index])\nparams = train_df[[\"img_path\", \"annotation\", \"width\", \"height\"]].iloc[index].to_dict()\nimg, msk = get_img_and_mask(**params)\nplot_img_and_mask(img, msk)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:21:20.079233Z","iopub.execute_input":"2021-10-25T10:21:20.079530Z","iopub.status.idle":"2021-10-25T10:21:21.122434Z","shell.execute_reply.started":"2021-10-25T10:21:20.079498Z","shell.execute_reply":"2021-10-25T10:21:21.121299Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## Cell: shsy5y ","metadata":{}},{"cell_type":"code","source":"for i in range(10):\n    img, msk = get_img_and_mask(**train_df[train_df.cell_type=='shsy5y'][[\"img_path\", \"annotation\", \"width\", \"height\"]].sample(10).reset_index(drop=True).iloc[i].to_dict())\n    plot_img_and_mask(img, msk)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:28:36.525572Z","iopub.execute_input":"2021-10-25T10:28:36.526319Z","iopub.status.idle":"2021-10-25T10:28:44.909155Z","shell.execute_reply.started":"2021-10-25T10:28:36.526279Z","shell.execute_reply":"2021-10-25T10:28:44.908513Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"## Cell: astro ","metadata":{}},{"cell_type":"code","source":"for i in range(10):\n    img, msk = get_img_and_mask(**train_df[train_df.cell_type=='astro'][[\"img_path\", \"annotation\", \"width\", \"height\"]].sample(10).reset_index(drop=True).iloc[i].to_dict())\n    plot_img_and_mask(img, msk)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:30:13.806679Z","iopub.execute_input":"2021-10-25T10:30:13.807041Z","iopub.status.idle":"2021-10-25T10:30:21.763352Z","shell.execute_reply.started":"2021-10-25T10:30:13.806998Z","shell.execute_reply":"2021-10-25T10:30:21.759595Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"## Cell: cort ","metadata":{}},{"cell_type":"code","source":"for i in range(10):\n    img, msk = get_img_and_mask(**train_df[train_df.cell_type=='cort'][[\"img_path\", \"annotation\", \"width\", \"height\"]].sample(10).reset_index(drop=True).iloc[i].to_dict())\n    plot_img_and_mask(img, msk)","metadata":{"execution":{"iopub.status.busy":"2021-10-25T10:30:26.802079Z","iopub.execute_input":"2021-10-25T10:30:26.802409Z","iopub.status.idle":"2021-10-25T10:30:33.642600Z","shell.execute_reply.started":"2021-10-25T10:30:26.802376Z","shell.execute_reply":"2021-10-25T10:30:33.641495Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"## Visualization Summary\n* Image with SHSY5Y\n    - Very dense, lot of cells per image\n    - Come in a variety of shapes\n    - Lots of overlapping cells\n    - Tends to be small relative to image size\n* Image with ASTRO\n    - The cell is large relative to image size\n    - The shape tends to be thin and long\n    - Contains Higly overlapping cells\n* Image with CORT\n    - The cell is small relative to image size\n    - Sparse, not a lot of cells per image\n    - The shape is round","metadata":{}},{"cell_type":"markdown","source":"## Overall Summary\n\n* There are three classes: shsy5y, astro, cort\n* There are 606 training images\n* There are 240 hidden test images\n* All images has width of 704, height of 520\n* Number of annotations: shsy5y=52286, astro=10522, cort=10777, total=73585\n    * This is an imbalance dataset\n    * There are in average 121 labels of cell per image\n        * Average labels/image for shsy5y: 337\n        * Average labels/image for astro: 80\n        * Average labels/image for cort: 33\n* There are three types of cells represented in the images, but only one type per image\n    * There are 320 images with CELL_TYPE=cort\n    * There are 155 images with CELL_TYPE=shsy5y\n    * There are 131 images with CELL_TYPE=astro\n","metadata":{}},{"cell_type":"markdown","source":"* Image with SHSY5Y\n    - Very dense, lot of cells per image\n    - Come in a variety of shapes\n    - Lots of overlapping cells\n    - Tends to be small relative to image size\n* Image with ASTRO\n    - The cell is large relative to image size\n    - The shape tends to be thin and long\n    - Contains Higly overlapping cells\n* Image with CORT\n    - The cell is small relative to image size\n    - Sparse, not a lot of cells per image\n    - The shape is round","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}